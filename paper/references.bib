
@book{Silge2022,
author = "Julia Silge and David Robinson", 
year = 2022,
title = "Text Mining with R",
publisher = "Printed by the author"
}

@MISC{Kaggle2019,
author = {Kaggle},
title = {Hamilton Lyrics},
month = Feb,
year = {2022},
howpublished={\url{https://www.kaggle.com/lbalter/hamilton-lyrics}}
}

@MISC{Wiki,
author = {Wikipedia},
title = {\emph{Hamilton} (musical)},
month = Feb,
year = {2022},
howpublished={\url{http://www.lextek.com/manuals/onix/stopwords1.html}}
}

@MISC{onix,
author = {bluehost},
title = {Lextek},
year = {2012},
howpublished={\url{https://en.wikipedia.org/wiki/Hamilton_(musical)}}
}


@article{nielsen11,
author = {Finn Äruprup Nielsen},
title = {A new ANEW: Evaluation of a word list for sentiment analysis in microblogs},
journal = {CoRR},
volume = {abs/1103.2903},
year = {2011},
url = {http://arxiv.org/abs/1103.2903},
archivePrefix = {arXiv},
biburl = {https://dblp.org/rec/bib/journals/corr/abs-1103-2903},
bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Lewis2004,
author = {Lewis, David D. and Yang, Yiming and Rose, Tony G. and Li, Fan},
title = {RCV1: A New Benchmark Collection for Text Categorization Research},
year = {2004},
issue_date = {12/1/2004},
publisher = {JMLR.org},
volume = {5},
issn = {1532-4435},
abstract = {Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually categorized newswire stories recently made available by Reuters, Ltd. for research purposes. Use of this data for research on text categorization requires a detailed understanding of the real world constraints under which the data was produced. Drawing on interviews with Reuters personnel and access to Reuters documentation, we describe the coding policy and quality control procedures used in producing the RCV1 data, the intended semantics of the hierarchical category taxonomies, and the corrections necessary to remove errorful data. We refer to the original data as RCV1-v1, and the corrected data as RCV1-v2. We benchmark several widely used supervised learning methods on RCV1-v2, illustrating the collection's properties, suggesting new directions for research, and providing baseline results for future studies. We make available detailed, per-category experimental results, as well as corrected versions of the category assignments and taxonomy structures, via online appendices.},
journal = {J. Mach. Learn. Res.},
month = {dec},
pages = {361–397},
numpages = {37}
}

@MISC{snowball,
  added-at = {2008-03-11T15:53:08.000+0100},
  author = {Porter, Martin F.},
  year = 2008,
  biburl = {https://www.bibsonomy.org/bibtex/2a0334d9771cea49e3d12e5d71180300f/danielt},
  howpublished = {Published online},
  interhash = {a9213c856a8b690e9ebe255096d91a83}
}

@article{mohammad2013,
author = {Mohammad, Saif and Turney, Peter},
year = {2013},
month = {01},
pages = {},
title = {NRC emotion lexicon},
doi = {10.4224/21270984}
}

@inproceedings{Hu2004,
author = {Hu, Minqing and Liu, Bing},
title = {Mining and Summarizing Customer Reviews},
booktitle = {Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
series = {KDD '04},
year = {2004},
isbn = {1-58113-888-1},
location = {Seattle, WA, USA},
pages = {168--177},
numpages = {10},
url = {http://doi.acm.org/10.1145/1014052.1014073},
doi = {10.1145/1014052.1014073},
acmid = {1014073},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {reviews, sentiment classification, summarization, text mining},
}

@article{Musen2015,
  author    = {Mark A. Musen},
  title     = {The prot{\'{e}}g{\'{e}} project: a look back and a look
               forward},
  journal   = {{AI} Matters},
  volume    = {1},
  number    = {4},
  pages     = {4--12},
  year      = {2015},
  url       = {https://doi.org/10.1145/2757001.2757003},
  doi       = {10.1145/2757001.2757003},
  timestamp = {Wed, 14 Nov 2018 10:27:16 +0100},
  biburl    = {https://dblp.org/rec/journals/aimatters/Musen15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Manual{sentimentr,
  title = {{sentimentr}: Calculate Text Polarity Sentiment},
  author = {Tyler W. Rinker},
  address = {Buffalo, New York},
  note = {version 2.9.0},
  year = {2021},
  url = {https://github.com/trinker/sentimentr},
}

 @misc{dass2018, 
 title={Create your chatbot using Python NLTK},
  url={https://medium.com/@ritidass29/create-your-chatbot-using-python-nltk-88809fa621d1},
   journal={Medium}, 
   author={Dass, Riti}, 
   year={2018}, 
   month={Sep}
} 

 @misc{khanna2021, 
 title={Text pre-processing: Stop words removal using different libraries}, url={https://towardsdatascience.com/text-pre-processing-stop-words-removal-using-different-libraries-f20bac19929a}, 
 journal={Medium}, 
 author={Khanna, Chetna}, 
 year={2021}, 
 month={Feb}
 } 
 
 @INPROCEEDINGS{shukla2017,
  author={Shukla, Stuti and Khanna, Pooja and Agrawal, Krishna Kant},
  booktitle={2017 International Conference on Infocom Technologies and Unmanned Systems (Trends and Future Directions) (ICTUS)}, 
  title={Review on sentiment analysis on music}, 
  year={2017},
  volume={},
  number={},
  pages={777-780},
  doi={10.1109/ICTUS.2017.8286111}}

@article{Yaavok2020,
    doi = {10.1371/journal.pone.0232525},
    author = {HaCohen-Kerner, Yaakov AND Miller, Daniel AND Yigal, Yair},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The influence of preprocessing on text classification using a bag-of-words representation},
    year = {2020},
    month = {05},
    volume = {15},
    url = {https://doi.org/10.1371/journal.pone.0232525},
    pages = {1-22},
    abstract = {Text classification (TC) is the task of automatically assigning documents to a fixed number of categories. TC is an important component in many text applications. Many of these applications perform preprocessing. There are different types of text preprocessing, e.g., conversion of uppercase letters into lowercase letters, HTML tag removal, stopword removal, punctuation mark removal, lemmatization, correction of common misspelled words, and reduction of replicated characters. We hypothesize that the application of different combinations of preprocessing methods can improve TC results. Therefore, we performed an extensive and systematic set of TC experiments (and this is our main research contribution) to explore the impact of all possible combinations of five/six basic preprocessing methods on four benchmark text corpora (and not samples of them) using three ML methods and training and test sets. The general conclusion (at least for the datasets verified) is that it is always advisable to perform an extensive and systematic variety of preprocessing methods combined with TC experiments because it contributes to improve TC accuracy. For all the tested datasets, there was always at least one combination of basic preprocessing methods that could be recommended to significantly improve the TC using a BOW representation. For three datasets, stopword removal was the only single preprocessing method that enabled a significant improvement compared to the baseline result using a bag of 1,000-word unigrams. For some of the datasets, there was minimal improvement when we removed HTML tags, performed spelling correction or removed punctuation marks, and reduced replicated characters. However, for the fourth dataset, the stopword removal was not beneficial. Instead, the conversion of uppercase letters into lowercase letters was the only single preprocessing method that demonstrated a significant improvement compared to the baseline result. The best result for this dataset was obtained when we performed spelling correction and conversion into lowercase letters. In general, for all the datasets processed, there was always at least one combination of basic preprocessing methods that could be recommended to improve the accuracy results when using a bag-of-words representation.},
    number = {5},

}